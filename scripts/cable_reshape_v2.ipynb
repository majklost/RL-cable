{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from gymnasium.wrappers import TimeLimit\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize,VecMonitor\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from deform_rl.envs.Cable_reshape_env.environment import CableReshapeV2,CableReshape\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3.common.callbacks import EvalCallback,BaseCallback\n",
    "\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment will not be deterministic\n",
      "Planning will not be deterministic\n",
      "seed for  BezierSampler  is  1903\n",
      "seed for  NDIMSampler  is  6822\n"
     ]
    }
   ],
   "source": [
    "def make_env(rank,seed=0):\n",
    "    \"\"\"\n",
    "    Utility function for multiprocessed env.\n",
    "\n",
    "    :param env_id: (str) the environment ID\n",
    "    :param seed: (int) the inital seed for RNG\n",
    "    :param rank: (int) index of the subprocess\n",
    "    \"\"\"\n",
    "    def _init():\n",
    "        env = CableReshapeV2(render_mode='human',seg_num=10,cable_length=300,scale_factor=800)\n",
    "        env = TimeLimit(env,max_episode_steps=1000)\n",
    "        env = Monitor(env)\n",
    "        # use a seed for reproducibility\n",
    "        # Important: use a different seed for each environment\n",
    "        # otherwise they would generate the same experiences\n",
    "        env.reset(seed=seed + rank)\n",
    "        return env\n",
    "\n",
    "    set_random_seed(seed)\n",
    "    return _init\n",
    "\n",
    "env0 = DummyVecEnv([make_env(i+4) for i in range(4)])\n",
    "training_env =VecNormalize(env0)\n",
    "env1 = DummyVecEnv([make_env(i+4) for i in range(1)])\n",
    "validation_env = VecNormalize(env1)\n",
    "\n",
    "save_dir = os.path.join(\"saved_models/reshape\")\n",
    "log_dir = os.path.join(\"logs/reshape\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "class SaveNormalizeCallback(BaseCallback):\n",
    "    def __init__(self, verbose = 0,):\n",
    "        super().__init__(verbose)\n",
    "\n",
    "    def _on_step(self):\n",
    "        training_env.save(save_dir+\"/vecnorms.pkl\")\n",
    "        super()._on_step()\n",
    "        return True\n",
    "save_callback = SaveNormalizeCallback()\n",
    "\n",
    "\n",
    "eval_callback = EvalCallback(\n",
    "    eval_env=validation_env,\n",
    "    n_eval_episodes=15,\n",
    "    eval_freq=10000,\n",
    "    callback_on_new_best=save_callback,\n",
    "    best_model_save_path=save_dir,\n",
    "    verbose=1,\n",
    "    render=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Logging to logs/reshape/reshape_v2_3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -4.75e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 2504      |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 3         |\n",
      "|    total_timesteps | 8192      |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -4.89e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1836       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 8          |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01305001 |\n",
      "|    clip_fraction        | 0.172      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -28.4      |\n",
      "|    explained_variance   | 0.933      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0156     |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0117    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 0.0216     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -4.83e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1600        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012852579 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.763       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0112     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 0.00911     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -4.85e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1558        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013320397 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.754       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0434     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00813    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.00684     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-4050.96 +/- 999.81\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | -4.05e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012756937 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.862       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.036      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.00573     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -5.06e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 1137      |\n",
      "|    iterations      | 5         |\n",
      "|    time_elapsed    | 36        |\n",
      "|    total_timesteps | 40960     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -4.89e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1184        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012698531 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00713    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.00568     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -4.96e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1215        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012441162 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0234     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0086     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.00242     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -4.83e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1240        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015604382 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.679       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0194     |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 0.00383     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | -4.77e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1256         |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 58           |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0140271615 |\n",
      "|    clip_fraction        | 0.18         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -28.4        |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00367     |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0135      |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 0.0016       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-3391.03 +/- 416.33\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | -3.39e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 80000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012591012 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.879       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0182     |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00541    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.00234     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -4.68e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 1105      |\n",
      "|    iterations      | 10        |\n",
      "|    time_elapsed    | 74        |\n",
      "|    total_timesteps | 81920     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -4.6e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1126        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014322305 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0176      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.00118     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -4.55e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1139        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014218167 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.5       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0179     |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.000979    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -4.45e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1137        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014135325 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0176     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.00103     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -4.31e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1142        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 100         |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014429997 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0155     |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 0.000796    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=-3163.14 +/- 597.00\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | -3.16e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 120000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015051493 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00407    |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 0.000875    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -4.18e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 1047      |\n",
      "|    iterations      | 15        |\n",
      "|    time_elapsed    | 117       |\n",
      "|    total_timesteps | 122880    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -4.17e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1052        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 124         |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015774153 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0291     |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00932    |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 0.00115     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -3.93e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1061        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 131         |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013383161 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.867       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00203     |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00787    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.00231     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -3.77e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1068        |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 138         |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015905697 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.4       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0392     |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.00105     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | -3.6e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1073         |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 145          |\n",
      "|    total_timesteps      | 155648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0147776455 |\n",
      "|    clip_fraction        | 0.192        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -28.3        |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.011       |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.0133      |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 0.000954     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=-2031.75 +/- 473.36\n",
      "Episode length: 1000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+03        |\n",
      "|    mean_reward          | -2.03e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 160000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0137143675 |\n",
      "|    clip_fraction        | 0.187        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -28.3        |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0113      |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.0133      |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 0.000879     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -3.44e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 1010      |\n",
      "|    iterations      | 20        |\n",
      "|    time_elapsed    | 162       |\n",
      "|    total_timesteps | 163840    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -3.21e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1019        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 168         |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015134178 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.3       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0288     |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 0.995       |\n",
      "|    value_loss           | 0.000801    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 997         |\n",
      "|    ep_rew_mean          | -3.09e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1028        |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016614046 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.2       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0101     |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 0.993       |\n",
      "|    value_loss           | 0.00112     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 997         |\n",
      "|    ep_rew_mean          | -2.96e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1035        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 181         |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016058216 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0289     |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 0.988       |\n",
      "|    value_loss           | 0.0158      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 997         |\n",
      "|    ep_rew_mean          | -2.82e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1042        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 188         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014728939 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.013       |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 0.988       |\n",
      "|    value_loss           | 0.00441     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=-1713.81 +/- 672.34\n",
      "Episode length: 952.00 +/- 179.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 952         |\n",
      "|    mean_reward          | -1.71e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 200000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015422321 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28.1       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0231     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 0.985       |\n",
      "|    value_loss           | 0.00459     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 997       |\n",
      "|    ep_rew_mean     | -2.73e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 1001      |\n",
      "|    iterations      | 25        |\n",
      "|    time_elapsed    | 204       |\n",
      "|    total_timesteps | 204800    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 997         |\n",
      "|    ep_rew_mean          | -2.61e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1011        |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 210         |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014689721 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0382     |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 0.983       |\n",
      "|    value_loss           | 0.00152     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 997         |\n",
      "|    ep_rew_mean          | -2.53e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1019        |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 216         |\n",
      "|    total_timesteps      | 221184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014155209 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -28         |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0512     |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 0.98        |\n",
      "|    value_loss           | 0.00204     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 997         |\n",
      "|    ep_rew_mean          | -2.37e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1027        |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 223         |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015375478 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.9       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0273     |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 0.977       |\n",
      "|    value_loss           | 0.00123     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 997        |\n",
      "|    ep_rew_mean          | -2.27e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1036       |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 229        |\n",
      "|    total_timesteps      | 237568     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01452644 |\n",
      "|    clip_fraction        | 0.193      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.9      |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0299    |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.0103    |\n",
      "|    std                  | 0.976      |\n",
      "|    value_loss           | 0.00136    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=-1436.20 +/- 526.12\n",
      "Episode length: 949.07 +/- 190.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 949         |\n",
      "|    mean_reward          | -1.44e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 240000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015359685 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00191     |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 0.974       |\n",
      "|    value_loss           | 0.000731    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 997       |\n",
      "|    ep_rew_mean     | -2.22e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 1004      |\n",
      "|    iterations      | 30        |\n",
      "|    time_elapsed    | 244       |\n",
      "|    total_timesteps | 245760    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 976         |\n",
      "|    ep_rew_mean          | -2.08e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1012        |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 250         |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015838303 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0299     |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 0.974       |\n",
      "|    value_loss           | 0.000879    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 952         |\n",
      "|    ep_rew_mean          | -1.96e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1019        |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 257         |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016183676 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.8       |\n",
      "|    explained_variance   | 0.888       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00634     |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00534    |\n",
      "|    std                  | 0.972       |\n",
      "|    value_loss           | 0.0641      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 922       |\n",
      "|    ep_rew_mean          | -1.84e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1027      |\n",
      "|    iterations           | 33        |\n",
      "|    time_elapsed         | 263       |\n",
      "|    total_timesteps      | 270336    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0177938 |\n",
      "|    clip_fraction        | 0.225     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -27.7     |\n",
      "|    explained_variance   | 0.92      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0162    |\n",
      "|    n_updates            | 320       |\n",
      "|    policy_gradient_loss | -0.00927  |\n",
      "|    std                  | 0.968     |\n",
      "|    value_loss           | 0.0601    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 884         |\n",
      "|    ep_rew_mean          | -1.72e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1034        |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 269         |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016456371 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.885       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0313      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00823    |\n",
      "|    std                  | 0.964       |\n",
      "|    value_loss           | 0.056       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=280000, episode_reward=-530.34 +/- 508.58\n",
      "Episode length: 534.93 +/- 381.68\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 535         |\n",
      "|    mean_reward          | -530        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 280000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015443971 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.934       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0265      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00963    |\n",
      "|    std                  | 0.964       |\n",
      "|    value_loss           | 0.0643      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 857      |\n",
      "|    ep_rew_mean     | -1.6e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 1021     |\n",
      "|    iterations      | 35       |\n",
      "|    time_elapsed    | 280      |\n",
      "|    total_timesteps | 286720   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 798         |\n",
      "|    ep_rew_mean          | -1.41e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1027        |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 286         |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015509877 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0194     |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 0.961       |\n",
      "|    value_loss           | 0.0404      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 741         |\n",
      "|    ep_rew_mean          | -1.19e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1034        |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 293         |\n",
      "|    total_timesteps      | 303104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017408494 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.906       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0519      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00847    |\n",
      "|    std                  | 0.962       |\n",
      "|    value_loss           | 0.0901      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 689         |\n",
      "|    ep_rew_mean          | -1.06e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1041        |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 298         |\n",
      "|    total_timesteps      | 311296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016795259 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.6       |\n",
      "|    explained_variance   | 0.924       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0145      |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 0.96        |\n",
      "|    value_loss           | 0.0632      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 661         |\n",
      "|    ep_rew_mean          | -966        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1046        |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 305         |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015775852 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0102     |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 0.958       |\n",
      "|    value_loss           | 0.0378      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=-641.36 +/- 920.45\n",
      "Episode length: 491.80 +/- 365.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 492         |\n",
      "|    mean_reward          | -641        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 320000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016480945 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.5       |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0337      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0094     |\n",
      "|    std                  | 0.958       |\n",
      "|    value_loss           | 0.0467      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 649      |\n",
      "|    ep_rew_mean     | -909     |\n",
      "| time/              |          |\n",
      "|    fps             | 1035     |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 316      |\n",
      "|    total_timesteps | 327680   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 643         |\n",
      "|    ep_rew_mean          | -858        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1041        |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 322         |\n",
      "|    total_timesteps      | 335872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018597912 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00717     |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 0.954       |\n",
      "|    value_loss           | 0.056       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 633         |\n",
      "|    ep_rew_mean          | -843        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1047        |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 328         |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016906109 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.4       |\n",
      "|    explained_variance   | 0.927       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.011      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 0.952       |\n",
      "|    value_loss           | 0.0419      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 617        |\n",
      "|    ep_rew_mean          | -786       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1053       |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 334        |\n",
      "|    total_timesteps      | 352256     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01665017 |\n",
      "|    clip_fraction        | 0.225      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.3      |\n",
      "|    explained_variance   | 0.916      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00898   |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.0116    |\n",
      "|    std                  | 0.951      |\n",
      "|    value_loss           | 0.0439     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=360000, episode_reward=-455.15 +/- 894.71\n",
      "Episode length: 377.20 +/- 313.99\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 377        |\n",
      "|    mean_reward          | -455       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 360000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01752262 |\n",
      "|    clip_fraction        | 0.232      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -27.3      |\n",
      "|    explained_variance   | 0.927      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00754   |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.0104    |\n",
      "|    std                  | 0.948      |\n",
      "|    value_loss           | 0.059      |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 576      |\n",
      "|    ep_rew_mean     | -726     |\n",
      "| time/              |          |\n",
      "|    fps             | 1047     |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 344      |\n",
      "|    total_timesteps | 360448   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 567         |\n",
      "|    ep_rew_mean          | -731        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1053        |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 350         |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017971955 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0185      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 0.948       |\n",
      "|    value_loss           | 0.0543      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 550         |\n",
      "|    ep_rew_mean          | -726        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1058        |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 355         |\n",
      "|    total_timesteps      | 376832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017061822 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.3       |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0073      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 0.947       |\n",
      "|    value_loss           | 0.0407      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 523         |\n",
      "|    ep_rew_mean          | -693        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1063        |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 361         |\n",
      "|    total_timesteps      | 385024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016711872 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00821     |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 0.944       |\n",
      "|    value_loss           | 0.0284      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 497         |\n",
      "|    ep_rew_mean          | -658        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1069        |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 367         |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017940504 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0749      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 0.943       |\n",
      "|    value_loss           | 0.0455      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=-512.00 +/- 943.79\n",
      "Episode length: 409.13 +/- 357.21\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 409         |\n",
      "|    mean_reward          | -512        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 400000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017637754 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.2       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0134     |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 0.942       |\n",
      "|    value_loss           | 0.0406      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 482      |\n",
      "|    ep_rew_mean     | -675     |\n",
      "| time/              |          |\n",
      "|    fps             | 1062     |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 377      |\n",
      "|    total_timesteps | 401408   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 511         |\n",
      "|    ep_rew_mean          | -753        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1067        |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 383         |\n",
      "|    total_timesteps      | 409600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017171267 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00969    |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    std                  | 0.938       |\n",
      "|    value_loss           | 0.0286      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 508         |\n",
      "|    ep_rew_mean          | -746        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1072        |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 389         |\n",
      "|    total_timesteps      | 417792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017706007 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0214      |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 0.937       |\n",
      "|    value_loss           | 0.0332      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 487         |\n",
      "|    ep_rew_mean          | -666        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1077        |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 395         |\n",
      "|    total_timesteps      | 425984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017183345 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0119      |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 0.936       |\n",
      "|    value_loss           | 0.0353      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 465         |\n",
      "|    ep_rew_mean          | -600        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1081        |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 401         |\n",
      "|    total_timesteps      | 434176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016320225 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00685     |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.009      |\n",
      "|    std                  | 0.939       |\n",
      "|    value_loss           | 0.0473      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=440000, episode_reward=-397.05 +/- 918.65\n",
      "Episode length: 321.20 +/- 273.06\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 321         |\n",
      "|    mean_reward          | -397        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 440000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016225267 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27.1       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0481      |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 0.937       |\n",
      "|    value_loss           | 0.0546      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 445      |\n",
      "|    ep_rew_mean     | -557     |\n",
      "| time/              |          |\n",
      "|    fps             | 1077     |\n",
      "|    iterations      | 54       |\n",
      "|    time_elapsed    | 410      |\n",
      "|    total_timesteps | 442368   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 434         |\n",
      "|    ep_rew_mean          | -539        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1081        |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 416         |\n",
      "|    total_timesteps      | 450560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017974108 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0121      |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 0.935       |\n",
      "|    value_loss           | 0.0385      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 434         |\n",
      "|    ep_rew_mean          | -578        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1086        |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 422         |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018403342 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0358     |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 0.933       |\n",
      "|    value_loss           | 0.0232      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 448         |\n",
      "|    ep_rew_mean          | -607        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1090        |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 428         |\n",
      "|    total_timesteps      | 466944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017812794 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -27         |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00482     |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 0.933       |\n",
      "|    value_loss           | 0.0224      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 452         |\n",
      "|    ep_rew_mean          | -670        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1094        |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 434         |\n",
      "|    total_timesteps      | 475136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017065648 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.9       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00843    |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 0.93        |\n",
      "|    value_loss           | 0.0283      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=-220.34 +/- 633.43\n",
      "Episode length: 289.40 +/- 279.46\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 289        |\n",
      "|    mean_reward          | -220       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 480000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01681876 |\n",
      "|    clip_fraction        | 0.225      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -26.9      |\n",
      "|    explained_variance   | 0.961      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.014     |\n",
      "|    n_updates            | 580        |\n",
      "|    policy_gradient_loss | -0.00982   |\n",
      "|    std                  | 0.928      |\n",
      "|    value_loss           | 0.0317     |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 483      |\n",
      "|    ep_rew_mean     | -800     |\n",
      "| time/              |          |\n",
      "|    fps             | 1091     |\n",
      "|    iterations      | 59       |\n",
      "|    time_elapsed    | 442      |\n",
      "|    total_timesteps | 483328   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 494         |\n",
      "|    ep_rew_mean          | -816        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1095        |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 448         |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018643104 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.9       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00289     |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 0.928       |\n",
      "|    value_loss           | 0.0235      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 472         |\n",
      "|    ep_rew_mean          | -734        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1098        |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 454         |\n",
      "|    total_timesteps      | 499712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017393406 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.9       |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0222      |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.00845    |\n",
      "|    std                  | 0.928       |\n",
      "|    value_loss           | 0.0445      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 443        |\n",
      "|    ep_rew_mean          | -632       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1102       |\n",
      "|    iterations           | 62         |\n",
      "|    time_elapsed         | 460        |\n",
      "|    total_timesteps      | 507904     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02058088 |\n",
      "|    clip_fraction        | 0.251      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -26.8      |\n",
      "|    explained_variance   | 0.945      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0073    |\n",
      "|    n_updates            | 610        |\n",
      "|    policy_gradient_loss | -0.0111    |\n",
      "|    std                  | 0.928      |\n",
      "|    value_loss           | 0.0447     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 420        |\n",
      "|    ep_rew_mean          | -554       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1105       |\n",
      "|    iterations           | 63         |\n",
      "|    time_elapsed         | 466        |\n",
      "|    total_timesteps      | 516096     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01808486 |\n",
      "|    clip_fraction        | 0.244      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -26.9      |\n",
      "|    explained_variance   | 0.939      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0251    |\n",
      "|    n_updates            | 620        |\n",
      "|    policy_gradient_loss | -0.0102    |\n",
      "|    std                  | 0.929      |\n",
      "|    value_loss           | 0.0565     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=520000, episode_reward=-346.71 +/- 762.33\n",
      "Episode length: 359.87 +/- 322.96\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | -347        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 520000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019852966 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.9       |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00531    |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 0.928       |\n",
      "|    value_loss           | 0.0604      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 404      |\n",
      "|    ep_rew_mean     | -472     |\n",
      "| time/              |          |\n",
      "|    fps             | 1100     |\n",
      "|    iterations      | 64       |\n",
      "|    time_elapsed    | 476      |\n",
      "|    total_timesteps | 524288   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 370         |\n",
      "|    ep_rew_mean          | -355        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1103        |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 482         |\n",
      "|    total_timesteps      | 532480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018949497 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.8       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0168     |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 0.928       |\n",
      "|    value_loss           | 0.0309      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 403         |\n",
      "|    ep_rew_mean          | -458        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1107        |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 488         |\n",
      "|    total_timesteps      | 540672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018738706 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.9       |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0306      |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 0.929       |\n",
      "|    value_loss           | 0.0525      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 405         |\n",
      "|    ep_rew_mean          | -481        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1110        |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 494         |\n",
      "|    total_timesteps      | 548864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018107194 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.9       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00298    |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 0.931       |\n",
      "|    value_loss           | 0.0293      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 418         |\n",
      "|    ep_rew_mean          | -518        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1113        |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 500         |\n",
      "|    total_timesteps      | 557056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018359441 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.9       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0143     |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 0.93        |\n",
      "|    value_loss           | 0.0295      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=560000, episode_reward=-329.78 +/- 980.15\n",
      "Episode length: 286.07 +/- 281.89\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 286         |\n",
      "|    mean_reward          | -330        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 560000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020176629 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.8       |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.01       |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 0.928       |\n",
      "|    value_loss           | 0.042       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 369      |\n",
      "|    ep_rew_mean     | -421     |\n",
      "| time/              |          |\n",
      "|    fps             | 1110     |\n",
      "|    iterations      | 69       |\n",
      "|    time_elapsed    | 509      |\n",
      "|    total_timesteps | 565248   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 337         |\n",
      "|    ep_rew_mean          | -343        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1112        |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 515         |\n",
      "|    total_timesteps      | 573440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018785436 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.8       |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00648    |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    std                  | 0.927       |\n",
      "|    value_loss           | 0.0437      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 342         |\n",
      "|    ep_rew_mean          | -329        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1115        |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 521         |\n",
      "|    total_timesteps      | 581632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017829407 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.8       |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0208     |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    std                  | 0.926       |\n",
      "|    value_loss           | 0.043       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 329         |\n",
      "|    ep_rew_mean          | -319        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1118        |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 527         |\n",
      "|    total_timesteps      | 589824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018270092 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.8       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0145      |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 0.926       |\n",
      "|    value_loss           | 0.0355      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 340         |\n",
      "|    ep_rew_mean          | -351        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1121        |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 533         |\n",
      "|    total_timesteps      | 598016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020471264 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.7       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0146      |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 0.921       |\n",
      "|    value_loss           | 0.0202      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=600000, episode_reward=-300.68 +/- 788.93\n",
      "Episode length: 328.33 +/- 339.12\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 328         |\n",
      "|    mean_reward          | -301        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 600000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019635182 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.7       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000928   |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 0.92        |\n",
      "|    value_loss           | 0.0214      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 359      |\n",
      "|    ep_rew_mean     | -412     |\n",
      "| time/              |          |\n",
      "|    fps             | 1117     |\n",
      "|    iterations      | 74       |\n",
      "|    time_elapsed    | 542      |\n",
      "|    total_timesteps | 606208   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 386         |\n",
      "|    ep_rew_mean          | -493        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1120        |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 548         |\n",
      "|    total_timesteps      | 614400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018298496 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.7       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0095     |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 0.92        |\n",
      "|    value_loss           | 0.0229      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 358         |\n",
      "|    ep_rew_mean          | -412        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1122        |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 554         |\n",
      "|    total_timesteps      | 622592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016981179 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.7       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0335     |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 0.92        |\n",
      "|    value_loss           | 0.025       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 382         |\n",
      "|    ep_rew_mean          | -460        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1125        |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 560         |\n",
      "|    total_timesteps      | 630784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019615559 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.7       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0062      |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 0.921       |\n",
      "|    value_loss           | 0.0386      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 368        |\n",
      "|    ep_rew_mean          | -421       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1128       |\n",
      "|    iterations           | 78         |\n",
      "|    time_elapsed         | 566        |\n",
      "|    total_timesteps      | 638976     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01988642 |\n",
      "|    clip_fraction        | 0.251      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -26.7      |\n",
      "|    explained_variance   | 0.969      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00332    |\n",
      "|    n_updates            | 770        |\n",
      "|    policy_gradient_loss | -0.0118    |\n",
      "|    std                  | 0.92       |\n",
      "|    value_loss           | 0.033      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=640000, episode_reward=-341.80 +/- 918.62\n",
      "Episode length: 323.47 +/- 318.71\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 323         |\n",
      "|    mean_reward          | -342        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 640000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019926026 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.7       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000251   |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    std                  | 0.92        |\n",
      "|    value_loss           | 0.0318      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 330      |\n",
      "|    ep_rew_mean     | -303     |\n",
      "| time/              |          |\n",
      "|    fps             | 1124     |\n",
      "|    iterations      | 79       |\n",
      "|    time_elapsed    | 575      |\n",
      "|    total_timesteps | 647168   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 282         |\n",
      "|    ep_rew_mean          | -191        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1126        |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 581         |\n",
      "|    total_timesteps      | 655360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020726698 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.6       |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00948     |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 0.919       |\n",
      "|    value_loss           | 0.047       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 292        |\n",
      "|    ep_rew_mean          | -230       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1129       |\n",
      "|    iterations           | 81         |\n",
      "|    time_elapsed         | 587        |\n",
      "|    total_timesteps      | 663552     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02076722 |\n",
      "|    clip_fraction        | 0.268      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -26.6      |\n",
      "|    explained_variance   | 0.968      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00902    |\n",
      "|    n_updates            | 800        |\n",
      "|    policy_gradient_loss | -0.0136    |\n",
      "|    std                  | 0.919      |\n",
      "|    value_loss           | 0.0317     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 281         |\n",
      "|    ep_rew_mean          | -216        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1131        |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 593         |\n",
      "|    total_timesteps      | 671744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019095335 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.6       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0217     |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 0.919       |\n",
      "|    value_loss           | 0.0328      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 280         |\n",
      "|    ep_rew_mean          | -215        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1133        |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 599         |\n",
      "|    total_timesteps      | 679936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021741226 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.6       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00549    |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 0.917       |\n",
      "|    value_loss           | 0.0343      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=680000, episode_reward=-175.41 +/- 710.66\n",
      "Episode length: 276.00 +/- 260.95\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 276       |\n",
      "|    mean_reward          | -175      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 680000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0196043 |\n",
      "|    clip_fraction        | 0.258     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -26.6     |\n",
      "|    explained_variance   | 0.964     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0289    |\n",
      "|    n_updates            | 830       |\n",
      "|    policy_gradient_loss | -0.0116   |\n",
      "|    std                  | 0.917     |\n",
      "|    value_loss           | 0.0452    |\n",
      "---------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 257      |\n",
      "|    ep_rew_mean     | -162     |\n",
      "| time/              |          |\n",
      "|    fps             | 1130     |\n",
      "|    iterations      | 84       |\n",
      "|    time_elapsed    | 608      |\n",
      "|    total_timesteps | 688128   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 266         |\n",
      "|    ep_rew_mean          | -182        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1132        |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 614         |\n",
      "|    total_timesteps      | 696320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020764507 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.6       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0231     |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 0.916       |\n",
      "|    value_loss           | 0.0265      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 264         |\n",
      "|    ep_rew_mean          | -165        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1135        |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 620         |\n",
      "|    total_timesteps      | 704512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019461792 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.5       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0102     |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 0.915       |\n",
      "|    value_loss           | 0.0311      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 258        |\n",
      "|    ep_rew_mean          | -155       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1137       |\n",
      "|    iterations           | 87         |\n",
      "|    time_elapsed         | 626        |\n",
      "|    total_timesteps      | 712704     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02042107 |\n",
      "|    clip_fraction        | 0.263      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -26.5      |\n",
      "|    explained_variance   | 0.96       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0122    |\n",
      "|    n_updates            | 860        |\n",
      "|    policy_gradient_loss | -0.0144    |\n",
      "|    std                  | 0.914      |\n",
      "|    value_loss           | 0.0416     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=720000, episode_reward=-69.30 +/- 567.31\n",
      "Episode length: 267.07 +/- 288.98\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 267        |\n",
      "|    mean_reward          | -69.3      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 720000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02045042 |\n",
      "|    clip_fraction        | 0.263      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -26.5      |\n",
      "|    explained_variance   | 0.975      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00219   |\n",
      "|    n_updates            | 870        |\n",
      "|    policy_gradient_loss | -0.0132    |\n",
      "|    std                  | 0.913      |\n",
      "|    value_loss           | 0.0323     |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 250      |\n",
      "|    ep_rew_mean     | -139     |\n",
      "| time/              |          |\n",
      "|    fps             | 1134     |\n",
      "|    iterations      | 88       |\n",
      "|    time_elapsed    | 635      |\n",
      "|    total_timesteps | 720896   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 234         |\n",
      "|    ep_rew_mean          | -111        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1135        |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 641         |\n",
      "|    total_timesteps      | 729088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022783255 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.5       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0346     |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 0.914       |\n",
      "|    value_loss           | 0.038       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 249         |\n",
      "|    ep_rew_mean          | -136        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1137        |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 647         |\n",
      "|    total_timesteps      | 737280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022500651 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.5       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0168      |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 0.913       |\n",
      "|    value_loss           | 0.0361      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 243         |\n",
      "|    ep_rew_mean          | -112        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1140        |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 653         |\n",
      "|    total_timesteps      | 745472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020578604 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.4       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0165     |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 0.91        |\n",
      "|    value_loss           | 0.027       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 248         |\n",
      "|    ep_rew_mean          | -123        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1142        |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 659         |\n",
      "|    total_timesteps      | 753664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021249048 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.4       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00427     |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 0.908       |\n",
      "|    value_loss           | 0.0293      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=760000, episode_reward=-35.27 +/- 515.13\n",
      "Episode length: 213.00 +/- 219.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 213         |\n",
      "|    mean_reward          | -35.3       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 760000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020642182 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.4       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.027       |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 0.908       |\n",
      "|    value_loss           | 0.0345      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 234      |\n",
      "|    ep_rew_mean     | -94.3    |\n",
      "| time/              |          |\n",
      "|    fps             | 1140     |\n",
      "|    iterations      | 93       |\n",
      "|    time_elapsed    | 668      |\n",
      "|    total_timesteps | 761856   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 229         |\n",
      "|    ep_rew_mean          | -114        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1142        |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 674         |\n",
      "|    total_timesteps      | 770048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022585178 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.4       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0174     |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 0.91        |\n",
      "|    value_loss           | 0.0309      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 218         |\n",
      "|    ep_rew_mean          | -104        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1143        |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 680         |\n",
      "|    total_timesteps      | 778240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020633139 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.4       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00387     |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 0.908       |\n",
      "|    value_loss           | 0.0262      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 222        |\n",
      "|    ep_rew_mean          | -115       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1144       |\n",
      "|    iterations           | 96         |\n",
      "|    time_elapsed         | 686        |\n",
      "|    total_timesteps      | 786432     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02180937 |\n",
      "|    clip_fraction        | 0.266      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -26.4      |\n",
      "|    explained_variance   | 0.979      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00895    |\n",
      "|    n_updates            | 950        |\n",
      "|    policy_gradient_loss | -0.0132    |\n",
      "|    std                  | 0.908      |\n",
      "|    value_loss           | 0.0262     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 216        |\n",
      "|    ep_rew_mean          | -71.8      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1146       |\n",
      "|    iterations           | 97         |\n",
      "|    time_elapsed         | 693        |\n",
      "|    total_timesteps      | 794624     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02159838 |\n",
      "|    clip_fraction        | 0.261      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -26.3      |\n",
      "|    explained_variance   | 0.981      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0298     |\n",
      "|    n_updates            | 960        |\n",
      "|    policy_gradient_loss | -0.014     |\n",
      "|    std                  | 0.905      |\n",
      "|    value_loss           | 0.0201     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=101.73 +/- 148.07\n",
      "Episode length: 149.67 +/- 50.92\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 150         |\n",
      "|    mean_reward          | 102         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 800000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021184936 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.3       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0019      |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 0.906       |\n",
      "|    value_loss           | 0.031       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 216      |\n",
      "|    ep_rew_mean     | -63      |\n",
      "| time/              |          |\n",
      "|    fps             | 1144     |\n",
      "|    iterations      | 98       |\n",
      "|    time_elapsed    | 701      |\n",
      "|    total_timesteps | 802816   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7d2f3e790bf0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PPO('MlpPolicy', training_env,device='cpu',verbose=1,tensorboard_log=log_dir)\n",
    "model.learn(800000,tb_log_name='reshape_v2',callback=eval_callback) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to logs/reshape/reshape_v2_3\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 186      |\n",
      "|    ep_rew_mean     | 26       |\n",
      "| time/              |          |\n",
      "|    fps             | 2227     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 1197220  |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1200000, episode_reward=74.56 +/- 575.17\n",
      "Episode length: 173.33 +/- 223.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 173         |\n",
      "|    mean_reward          | 74.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1200000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024974246 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.4       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0268     |\n",
      "|    n_updates            | 1460        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 0.864       |\n",
      "|    value_loss           | 0.046       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 155      |\n",
      "|    ep_rew_mean     | 99.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 1369     |\n",
      "|    iterations      | 2        |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 1205412  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 146         |\n",
      "|    ep_rew_mean          | 128         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1278        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 1213604     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026838584 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.3       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00287     |\n",
      "|    n_updates            | 1470        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 0.862       |\n",
      "|    value_loss           | 0.0435      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 160        |\n",
      "|    ep_rew_mean          | 107        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1239       |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 26         |\n",
      "|    total_timesteps      | 1221796    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02439285 |\n",
      "|    clip_fraction        | 0.316      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -25.3      |\n",
      "|    explained_variance   | 0.941      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0256    |\n",
      "|    n_updates            | 1480       |\n",
      "|    policy_gradient_loss | -0.0126    |\n",
      "|    std                  | 0.861      |\n",
      "|    value_loss           | 0.0627     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 158         |\n",
      "|    ep_rew_mean          | 114         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1215        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 1229988     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024546476 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.3       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.021       |\n",
      "|    n_updates            | 1490        |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 0.862       |\n",
      "|    value_loss           | 0.0537      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 160         |\n",
      "|    ep_rew_mean          | 105         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1201        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 1238180     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025687952 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.3       |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0302      |\n",
      "|    n_updates            | 1500        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 0.863       |\n",
      "|    value_loss           | 0.0604      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1240000, episode_reward=204.34 +/- 39.59\n",
      "Episode length: 125.13 +/- 26.71\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 125         |\n",
      "|    mean_reward          | 204         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1240000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026327055 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.3       |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0122     |\n",
      "|    n_updates            | 1510        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 0.863       |\n",
      "|    value_loss           | 0.054       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 152      |\n",
      "|    ep_rew_mean     | 118      |\n",
      "| time/              |          |\n",
      "|    fps             | 1175     |\n",
      "|    iterations      | 7        |\n",
      "|    time_elapsed    | 48       |\n",
      "|    total_timesteps | 1246372  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 135        |\n",
      "|    ep_rew_mean          | 149        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1179       |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 55         |\n",
      "|    total_timesteps      | 1254564    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02557111 |\n",
      "|    clip_fraction        | 0.308      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -25.3      |\n",
      "|    explained_variance   | 0.953      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0206     |\n",
      "|    n_updates            | 1520       |\n",
      "|    policy_gradient_loss | -0.0121    |\n",
      "|    std                  | 0.861      |\n",
      "|    value_loss           | 0.0522     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 157        |\n",
      "|    ep_rew_mean          | 88.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1185       |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 62         |\n",
      "|    total_timesteps      | 1262756    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02369371 |\n",
      "|    clip_fraction        | 0.3        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -25.3      |\n",
      "|    explained_variance   | 0.963      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00961   |\n",
      "|    n_updates            | 1530       |\n",
      "|    policy_gradient_loss | -0.0113    |\n",
      "|    std                  | 0.86       |\n",
      "|    value_loss           | 0.0459     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 176         |\n",
      "|    ep_rew_mean          | 36.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1185        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 1270948     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025953323 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.3       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00268     |\n",
      "|    n_updates            | 1540        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 0.859       |\n",
      "|    value_loss           | 0.0362      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 153         |\n",
      "|    ep_rew_mean          | 91.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1194        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 1279140     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023985285 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.2       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0353     |\n",
      "|    n_updates            | 1550        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 0.858       |\n",
      "|    value_loss           | 0.0413      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1280000, episode_reward=212.58 +/- 59.81\n",
      "Episode length: 111.93 +/- 24.96\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 112         |\n",
      "|    mean_reward          | 213         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1280000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027914055 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.2       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0069      |\n",
      "|    n_updates            | 1560        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 0.858       |\n",
      "|    value_loss           | 0.0531      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 138      |\n",
      "|    ep_rew_mean     | 130      |\n",
      "| time/              |          |\n",
      "|    fps             | 1187     |\n",
      "|    iterations      | 12       |\n",
      "|    time_elapsed    | 82       |\n",
      "|    total_timesteps | 1287332  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 151         |\n",
      "|    ep_rew_mean          | 96.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1195        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 1295524     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026309492 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.2       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0422     |\n",
      "|    n_updates            | 1570        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 0.857       |\n",
      "|    value_loss           | 0.0461      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 159         |\n",
      "|    ep_rew_mean          | 77.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1205        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 1303716     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025653232 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.2       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00599     |\n",
      "|    n_updates            | 1580        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    std                  | 0.856       |\n",
      "|    value_loss           | 0.0435      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 153         |\n",
      "|    ep_rew_mean          | 102         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1213        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 1311908     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027612895 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.2       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0252     |\n",
      "|    n_updates            | 1590        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 0.854       |\n",
      "|    value_loss           | 0.0349      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1320000, episode_reward=-11.01 +/- 781.54\n",
      "Episode length: 173.87 +/- 223.52\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 174         |\n",
      "|    mean_reward          | -11         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1320000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028651254 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.1       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0201     |\n",
      "|    n_updates            | 1600        |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 0.851       |\n",
      "|    value_loss           | 0.0494      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 147      |\n",
      "|    ep_rew_mean     | 130      |\n",
      "| time/              |          |\n",
      "|    fps             | 1200     |\n",
      "|    iterations      | 16       |\n",
      "|    time_elapsed    | 109      |\n",
      "|    total_timesteps | 1320100  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 147         |\n",
      "|    ep_rew_mean          | 128         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1201        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 1328292     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025997158 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.1       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0187      |\n",
      "|    n_updates            | 1610        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 0.852       |\n",
      "|    value_loss           | 0.0534      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 155         |\n",
      "|    ep_rew_mean          | 106         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1202        |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 122         |\n",
      "|    total_timesteps      | 1336484     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025740393 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.1       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00425     |\n",
      "|    n_updates            | 1620        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 0.852       |\n",
      "|    value_loss           | 0.0452      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 179         |\n",
      "|    ep_rew_mean          | 40.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1201        |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 129         |\n",
      "|    total_timesteps      | 1344676     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023150356 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.1       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0042      |\n",
      "|    n_updates            | 1630        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 0.852       |\n",
      "|    value_loss           | 0.0426      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 173         |\n",
      "|    ep_rew_mean          | 59.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1205        |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 1352868     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025598142 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.1       |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00549     |\n",
      "|    n_updates            | 1640        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 0.853       |\n",
      "|    value_loss           | 0.0419      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1360000, episode_reward=222.68 +/- 34.80\n",
      "Episode length: 114.20 +/- 28.38\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 114         |\n",
      "|    mean_reward          | 223         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1360000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025400117 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.1       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00613    |\n",
      "|    n_updates            | 1650        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 0.852       |\n",
      "|    value_loss           | 0.0461      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 147      |\n",
      "|    ep_rew_mean     | 127      |\n",
      "| time/              |          |\n",
      "|    fps             | 1200     |\n",
      "|    iterations      | 21       |\n",
      "|    time_elapsed    | 143      |\n",
      "|    total_timesteps | 1361060  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 143        |\n",
      "|    ep_rew_mean          | 132        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1204       |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 149        |\n",
      "|    total_timesteps      | 1369252    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02867019 |\n",
      "|    clip_fraction        | 0.33       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -25.1      |\n",
      "|    explained_variance   | 0.964      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0253    |\n",
      "|    n_updates            | 1660       |\n",
      "|    policy_gradient_loss | -0.0132    |\n",
      "|    std                  | 0.851      |\n",
      "|    value_loss           | 0.0417     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 141         |\n",
      "|    ep_rew_mean          | 143         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1204        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 156         |\n",
      "|    total_timesteps      | 1377444     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027153049 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25.1       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00739     |\n",
      "|    n_updates            | 1670        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    std                  | 0.851       |\n",
      "|    value_loss           | 0.0462      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 151         |\n",
      "|    ep_rew_mean          | 116         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1207        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 162         |\n",
      "|    total_timesteps      | 1385636     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027121473 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25         |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00311    |\n",
      "|    n_updates            | 1680        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 0.85        |\n",
      "|    value_loss           | 0.0503      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 160         |\n",
      "|    ep_rew_mean          | 96.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1208        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 169         |\n",
      "|    total_timesteps      | 1393828     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025771385 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25         |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0177     |\n",
      "|    n_updates            | 1690        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    std                  | 0.848       |\n",
      "|    value_loss           | 0.032       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1400000, episode_reward=235.51 +/- 27.15\n",
      "Episode length: 108.87 +/- 23.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 109        |\n",
      "|    mean_reward          | 236        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1400000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02741767 |\n",
      "|    clip_fraction        | 0.33       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -25        |\n",
      "|    explained_variance   | 0.959      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0262     |\n",
      "|    n_updates            | 1700       |\n",
      "|    policy_gradient_loss | -0.0162    |\n",
      "|    std                  | 0.848      |\n",
      "|    value_loss           | 0.038      |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 150      |\n",
      "|    ep_rew_mean     | 124      |\n",
      "| time/              |          |\n",
      "|    fps             | 1203     |\n",
      "|    iterations      | 26       |\n",
      "|    time_elapsed    | 177      |\n",
      "|    total_timesteps | 1402020  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 157         |\n",
      "|    ep_rew_mean          | 117         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1206        |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 183         |\n",
      "|    total_timesteps      | 1410212     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027528271 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -25         |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00361     |\n",
      "|    n_updates            | 1710        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 0.847       |\n",
      "|    value_loss           | 0.0487      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 170         |\n",
      "|    ep_rew_mean          | 97.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1207        |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 189         |\n",
      "|    total_timesteps      | 1418404     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025032658 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -24.9       |\n",
      "|    explained_variance   | 0.927       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0356      |\n",
      "|    n_updates            | 1720        |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 0.845       |\n",
      "|    value_loss           | 0.0623      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 183         |\n",
      "|    ep_rew_mean          | 57.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1207        |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 196         |\n",
      "|    total_timesteps      | 1426596     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028352601 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -24.9       |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00212     |\n",
      "|    n_updates            | 1730        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    std                  | 0.845       |\n",
      "|    value_loss           | 0.0518      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 178         |\n",
      "|    ep_rew_mean          | 62.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1206        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 203         |\n",
      "|    total_timesteps      | 1434788     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025635177 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -24.9       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0325     |\n",
      "|    n_updates            | 1740        |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    std                  | 0.843       |\n",
      "|    value_loss           | 0.0461      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1440000, episode_reward=190.29 +/- 113.53\n",
      "Episode length: 118.87 +/- 44.65\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 119         |\n",
      "|    mean_reward          | 190         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1440000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027820414 |\n",
      "|    clip_fraction        | 0.332       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -24.9       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0245     |\n",
      "|    n_updates            | 1750        |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 0.844       |\n",
      "|    value_loss           | 0.0493      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 168      |\n",
      "|    ep_rew_mean     | 70.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 1197     |\n",
      "|    iterations      | 31       |\n",
      "|    time_elapsed    | 212      |\n",
      "|    total_timesteps | 1442980  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 157        |\n",
      "|    ep_rew_mean          | 97         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1199       |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 218        |\n",
      "|    total_timesteps      | 1451172    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02741478 |\n",
      "|    clip_fraction        | 0.328      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -24.9      |\n",
      "|    explained_variance   | 0.962      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00784    |\n",
      "|    n_updates            | 1760       |\n",
      "|    policy_gradient_loss | -0.015     |\n",
      "|    std                  | 0.843      |\n",
      "|    value_loss           | 0.0442     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 149         |\n",
      "|    ep_rew_mean          | 116         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1202        |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 224         |\n",
      "|    total_timesteps      | 1459364     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025173033 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -24.8       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0237     |\n",
      "|    n_updates            | 1770        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 0.842       |\n",
      "|    value_loss           | 0.0445      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 156         |\n",
      "|    ep_rew_mean          | 113         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1203        |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 231         |\n",
      "|    total_timesteps      | 1467556     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027429162 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -24.8       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0303     |\n",
      "|    n_updates            | 1780        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 0.841       |\n",
      "|    value_loss           | 0.0486      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 152         |\n",
      "|    ep_rew_mean          | 118         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1203        |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 238         |\n",
      "|    total_timesteps      | 1475748     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026358165 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -24.7       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0214     |\n",
      "|    n_updates            | 1790        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 0.836       |\n",
      "|    value_loss           | 0.0511      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1480000, episode_reward=204.76 +/- 52.53\n",
      "Episode length: 115.80 +/- 19.19\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 116         |\n",
      "|    mean_reward          | 205         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1480000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027090073 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -24.7       |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0468     |\n",
      "|    n_updates            | 1800        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 0.836       |\n",
      "|    value_loss           | 0.034       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 151      |\n",
      "|    ep_rew_mean     | 112      |\n",
      "| time/              |          |\n",
      "|    fps             | 1194     |\n",
      "|    iterations      | 36       |\n",
      "|    time_elapsed    | 246      |\n",
      "|    total_timesteps | 1483940  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 187         |\n",
      "|    ep_rew_mean          | 16.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1195        |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 253         |\n",
      "|    total_timesteps      | 1492132     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025502209 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -24.6       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00929    |\n",
      "|    n_updates            | 1810        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 0.834       |\n",
      "|    value_loss           | 0.0301      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 178         |\n",
      "|    ep_rew_mean          | 40.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1196        |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 1500324     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026476484 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -24.6       |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0116      |\n",
      "|    n_updates            | 1820        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    std                  | 0.833       |\n",
      "|    value_loss           | 0.0301      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 153        |\n",
      "|    ep_rew_mean          | 108        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1199       |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 266        |\n",
      "|    total_timesteps      | 1508516    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03057334 |\n",
      "|    clip_fraction        | 0.343      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -24.5      |\n",
      "|    explained_variance   | 0.963      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0288    |\n",
      "|    n_updates            | 1830       |\n",
      "|    policy_gradient_loss | -0.0142    |\n",
      "|    std                  | 0.829      |\n",
      "|    value_loss           | 0.0381     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 148         |\n",
      "|    ep_rew_mean          | 112         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1202        |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 272         |\n",
      "|    total_timesteps      | 1516708     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026352618 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -24.5       |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00478     |\n",
      "|    n_updates            | 1840        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 0.828       |\n",
      "|    value_loss           | 0.0434      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1520000, episode_reward=229.84 +/- 37.00\n",
      "Episode length: 116.87 +/- 28.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 117         |\n",
      "|    mean_reward          | 230         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1520000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027787037 |\n",
      "|    clip_fraction        | 0.329       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -24.5       |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0149     |\n",
      "|    n_updates            | 1850        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 0.828       |\n",
      "|    value_loss           | 0.0416      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 139      |\n",
      "|    ep_rew_mean     | 149      |\n",
      "| time/              |          |\n",
      "|    fps             | 1199     |\n",
      "|    iterations      | 41       |\n",
      "|    time_elapsed    | 279      |\n",
      "|    total_timesteps | 1524900  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 139         |\n",
      "|    ep_rew_mean          | 151         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1201        |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 286         |\n",
      "|    total_timesteps      | 1533092     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026184717 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -24.5       |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0142      |\n",
      "|    n_updates            | 1860        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 0.827       |\n",
      "|    value_loss           | 0.0472      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 129         |\n",
      "|    ep_rew_mean          | 162         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1203        |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 292         |\n",
      "|    total_timesteps      | 1541284     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027918003 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -24.5       |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0159      |\n",
      "|    n_updates            | 1870        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 0.828       |\n",
      "|    value_loss           | 0.0325      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 130         |\n",
      "|    ep_rew_mean          | 169         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1203        |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 299         |\n",
      "|    total_timesteps      | 1549476     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027584504 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -24.5       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0295     |\n",
      "|    n_updates            | 1880        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 0.827       |\n",
      "|    value_loss           | 0.0421      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 147        |\n",
      "|    ep_rew_mean          | 132        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1201       |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 306        |\n",
      "|    total_timesteps      | 1557668    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02602575 |\n",
      "|    clip_fraction        | 0.316      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -24.4      |\n",
      "|    explained_variance   | 0.954      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0119    |\n",
      "|    n_updates            | 1890       |\n",
      "|    policy_gradient_loss | -0.0143    |\n",
      "|    std                  | 0.826      |\n",
      "|    value_loss           | 0.0446     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1560000, episode_reward=221.85 +/- 42.67\n",
      "Episode length: 118.67 +/- 26.89\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 119         |\n",
      "|    mean_reward          | 222         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1560000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026224475 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -24.4       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0223      |\n",
      "|    n_updates            | 1900        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 0.826       |\n",
      "|    value_loss           | 0.0405      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 159      |\n",
      "|    ep_rew_mean     | 100      |\n",
      "| time/              |          |\n",
      "|    fps             | 1196     |\n",
      "|    iterations      | 46       |\n",
      "|    time_elapsed    | 315      |\n",
      "|    total_timesteps | 1565860  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 177         |\n",
      "|    ep_rew_mean          | 44.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1195        |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 322         |\n",
      "|    total_timesteps      | 1574052     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027193654 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -24.4       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0302      |\n",
      "|    n_updates            | 1910        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    std                  | 0.824       |\n",
      "|    value_loss           | 0.0505      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 184         |\n",
      "|    ep_rew_mean          | 30.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1194        |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 329         |\n",
      "|    total_timesteps      | 1582244     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029928263 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -24.4       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0449     |\n",
      "|    n_updates            | 1920        |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 0.823       |\n",
      "|    value_loss           | 0.034       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 211         |\n",
      "|    ep_rew_mean          | -34.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1196        |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 335         |\n",
      "|    total_timesteps      | 1590436     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027460523 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -24.3       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0271      |\n",
      "|    n_updates            | 1930        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 0.822       |\n",
      "|    value_loss           | 0.0537      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 174        |\n",
      "|    ep_rew_mean          | 88.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1196       |\n",
      "|    iterations           | 50         |\n",
      "|    time_elapsed         | 342        |\n",
      "|    total_timesteps      | 1598628    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02825331 |\n",
      "|    clip_fraction        | 0.325      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -24.3      |\n",
      "|    explained_variance   | 0.957      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0104    |\n",
      "|    n_updates            | 1940       |\n",
      "|    policy_gradient_loss | -0.015     |\n",
      "|    std                  | 0.822      |\n",
      "|    value_loss           | 0.0539     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1600000, episode_reward=192.92 +/- 56.40\n",
      "Episode length: 151.93 +/- 83.17\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 152        |\n",
      "|    mean_reward          | 193        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1600000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02692734 |\n",
      "|    clip_fraction        | 0.324      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -24.3      |\n",
      "|    explained_variance   | 0.925      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0229    |\n",
      "|    n_updates            | 1950       |\n",
      "|    policy_gradient_loss | -0.0126    |\n",
      "|    std                  | 0.821      |\n",
      "|    value_loss           | 0.0724     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 142      |\n",
      "|    ep_rew_mean     | 163      |\n",
      "| time/              |          |\n",
      "|    fps             | 1193     |\n",
      "|    iterations      | 51       |\n",
      "|    time_elapsed    | 350      |\n",
      "|    total_timesteps | 1606820  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 139        |\n",
      "|    ep_rew_mean          | 163        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1193       |\n",
      "|    iterations           | 52         |\n",
      "|    time_elapsed         | 357        |\n",
      "|    total_timesteps      | 1615012    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02807761 |\n",
      "|    clip_fraction        | 0.328      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -24.3      |\n",
      "|    explained_variance   | 0.931      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00386    |\n",
      "|    n_updates            | 1960       |\n",
      "|    policy_gradient_loss | -0.0115    |\n",
      "|    std                  | 0.82       |\n",
      "|    value_loss           | 0.0724     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 129         |\n",
      "|    ep_rew_mean          | 177         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1189        |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 365         |\n",
      "|    total_timesteps      | 1623204     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031445734 |\n",
      "|    clip_fraction        | 0.343       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -24.3       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0327      |\n",
      "|    n_updates            | 1970        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 0.818       |\n",
      "|    value_loss           | 0.0682      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 143         |\n",
      "|    ep_rew_mean          | 146         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1188        |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 372         |\n",
      "|    total_timesteps      | 1631396     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031612832 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -24.2       |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.5e-05     |\n",
      "|    n_updates            | 1980        |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 0.817       |\n",
      "|    value_loss           | 0.0574      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 142         |\n",
      "|    ep_rew_mean          | 146         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1188        |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 379         |\n",
      "|    total_timesteps      | 1639588     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027660634 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -24.2       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00416     |\n",
      "|    n_updates            | 1990        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 0.817       |\n",
      "|    value_loss           | 0.0666      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1640000, episode_reward=209.93 +/- 70.53\n",
      "Episode length: 127.33 +/- 44.35\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 127         |\n",
      "|    mean_reward          | 210         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1640000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026401527 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -24.2       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0176     |\n",
      "|    n_updates            | 2000        |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    std                  | 0.817       |\n",
      "|    value_loss           | 0.0398      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 155      |\n",
      "|    ep_rew_mean     | 97.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 1184     |\n",
      "|    iterations      | 56       |\n",
      "|    time_elapsed    | 387      |\n",
      "|    total_timesteps | 1647780  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 150         |\n",
      "|    ep_rew_mean          | 127         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1185        |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 393         |\n",
      "|    total_timesteps      | 1655972     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030769981 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -24.2       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0304      |\n",
      "|    n_updates            | 2010        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 0.816       |\n",
      "|    value_loss           | 0.0585      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 139         |\n",
      "|    ep_rew_mean          | 150         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1187        |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 400         |\n",
      "|    total_timesteps      | 1664164     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026490469 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -24.2       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00115     |\n",
      "|    n_updates            | 2020        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    std                  | 0.814       |\n",
      "|    value_loss           | 0.0454      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1600000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreshape_v2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \n",
      "File \u001b[0;32m~/Documents/Skola/bakalarka/RL/RL-cable/.venv/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:311\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[1;32m    304\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    310\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[0;32m--> 311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Skola/bakalarka/RL/RL-cable/.venv/lib/python3.12/site-packages/stable_baselines3/common/on_policy_algorithm.py:323\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 323\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Skola/bakalarka/RL/RL-cable/.venv/lib/python3.12/site-packages/stable_baselines3/common/on_policy_algorithm.py:218\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;66;03m# Otherwise, clip the actions to avoid out of bound error\u001b[39;00m\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;66;03m# as we are sampling from an unbounded Gaussian distribution\u001b[39;00m\n\u001b[1;32m    216\u001b[0m         clipped_actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mlow, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mhigh)\n\u001b[0;32m--> 218\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclipped_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[1;32m    222\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Skola/bakalarka/RL/RL-cable/.venv/lib/python3.12/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Skola/bakalarka/RL/RL-cable/.venv/lib/python3.12/site-packages/stable_baselines3/common/vec_env/vec_normalize.py:181\u001b[0m, in \u001b[0;36mVecNormalize.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m    175\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;124;03m    Apply sequence of actions to sequence of environments\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03m    actions -> (observations, rewards, dones)\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m    where ``dones`` is a boolean vector indicating whether each element is new.\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m     obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvenv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obs, (np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mdict\u001b[39m))  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mold_obs \u001b[38;5;241m=\u001b[39m obs\n",
      "File \u001b[0;32m~/Documents/Skola/bakalarka/RL/RL-cable/.venv/lib/python3.12/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:70\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx]:\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;66;03m# save final observation where user can get it, then reset\u001b[39;00m\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mterminal_observation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m obs\n\u001b[0;32m---> 70\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_obs(env_idx, obs)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obs_from_buf(), np\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews), np\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones), deepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos))\n",
      "File \u001b[0;32m~/Documents/Skola/bakalarka/RL/RL-cable/.venv/lib/python3.12/site-packages/stable_baselines3/common/monitor.py:83\u001b[0m, in \u001b[0;36mMonitor.reset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected you to pass keyword argument \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m into reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_reset_info[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Skola/bakalarka/RL/RL-cable/.venv/lib/python3.12/site-packages/gymnasium/wrappers/common.py:146\u001b[0m, in \u001b[0;36mTimeLimit.reset\u001b[0;34m(self, seed, options)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resets the environment with :param:`**kwargs` and sets the number of steps elapsed to zero.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03m    The reset environment\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Skola/bakalarka/RL/RL-cable/.venv/lib/python3.12/site-packages/gymnasium/core.py:328\u001b[0m, in \u001b[0;36mWrapper.reset\u001b[0;34m(self, seed, options)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, seed: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, options: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    326\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    327\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`reset` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Skola/bakalarka/RL/RL-cable/deform_rl/envs/Cable_reshape_env/environment.py:99\u001b[0m, in \u001b[0;36mCableReshape.reset\u001b[0;34m(self, seed, options)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msim\u001b[38;5;241m.\u001b[39mimport_from(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexported_sim)\n\u001b[0;32m---> 99\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_distance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calc_distance(ctrl_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    101\u001b[0m info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_info()\n",
      "File \u001b[0;32m~/Documents/Skola/bakalarka/RL/RL-cable/deform_rl/envs/Cable_reshape_env/environment.py:93\u001b[0m, in \u001b[0;36mCableReshape._get_target\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_target\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Skola/bakalarka/RL/RL-cable/deform_rl/envs/sim/samplers/bezier_sampler.py:61\u001b[0m, in \u001b[0;36mBezierSampler.sample\u001b[0;34m(self, x, y, angle, fixed_shape)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(\u001b[38;5;28mself\u001b[39m, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, angle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, fixed_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m angle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 61\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample_goal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mangle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfixed_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     xo, yo, angleo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim_sampler\u001b[38;5;241m.\u001b[39msample()\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample_inner(xo, yo, angleo)\n",
      "File \u001b[0;32m~/Documents/Skola/bakalarka/RL/RL-cable/deform_rl/envs/sim/samplers/bezier_sampler.py:98\u001b[0m, in \u001b[0;36mBezierSampler._sample_goal\u001b[0;34m(self, x, y, angle, fixed_shape)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrng \u001b[38;5;241m=\u001b[39m old_rng\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manglef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m points\n",
      "File \u001b[0;32m~/Documents/Skola/bakalarka/RL/RL-cable/deform_rl/envs/sim/samplers/bezier_sampler.py:68\u001b[0m, in \u001b[0;36mBezierSampler._sample_inner\u001b[0;34m(self, x, y, angle)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sample_inner\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y, angle):\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_random_queries \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 68\u001b[0m     curve_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_curve_points\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mangle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     directions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calc_directions(curve_points)\n\u001b[1;32m     71\u001b[0m     dir_lengths \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(d) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m directions]\n",
      "File \u001b[0;32m~/Documents/Skola/bakalarka/RL/RL-cable/deform_rl/envs/sim/samplers/bezier_sampler.py:110\u001b[0m, in \u001b[0;36mBezierSampler._get_curve_points\u001b[0;34m(self, x, y, angle)\u001b[0m\n\u001b[1;32m    107\u001b[0m D \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    108\u001b[0m bezier \u001b[38;5;241m=\u001b[39m create_bezier(A, B, C, D)\n\u001b[0;32m--> 110\u001b[0m points \u001b[38;5;241m=\u001b[39m [rot_matrix(angle) \u001b[38;5;241m@\u001b[39m bezier(t) \u001b[38;5;241m+\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m           \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcable_segments_num \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m points\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model.learn(1600000,tb_log_name='reshape_v2',callback=eval_callback,reset_num_timesteps=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
